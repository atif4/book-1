{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA pamages \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Data Viz pakages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide earrings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\haier\\\\Downloads\\\\covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
       "      <td>astroworld</td>\n",
       "      <td>wednesday addams as a disney princess keepin i...</td>\n",
       "      <td>2017-05-26 05:46:42</td>\n",
       "      <td>624</td>\n",
       "      <td>950</td>\n",
       "      <td>18775</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Basile üá∫üá∏</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
       "      <td>2009-04-16 20:06:23</td>\n",
       "      <td>2253</td>\n",
       "      <td>1677</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time4fisticuffs</td>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
       "      <td>2009-02-28 18:57:41</td>\n",
       "      <td>9275</td>\n",
       "      <td>9525</td>\n",
       "      <td>7254</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethel mertz</td>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
       "      <td>2019-03-07 01:45:06</td>\n",
       "      <td>197</td>\n",
       "      <td>987</td>\n",
       "      <td>1488</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPR-J&amp;K</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>üñäÔ∏èOfficial Twitter handle of Department of Inf...</td>\n",
       "      <td>2017-02-12 06:45:15</td>\n",
       "      <td>101009</td>\n",
       "      <td>168</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>AJIMATI AbdulRahman O.</td>\n",
       "      <td>Ilorin, Nigeria</td>\n",
       "      <td>Animal Scientist|| Muslim|| Real Madrid/Chelsea</td>\n",
       "      <td>2013-12-30 18:59:19</td>\n",
       "      <td>412</td>\n",
       "      <td>1609</td>\n",
       "      <td>1062</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:21</td>\n",
       "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
       "      <td>['WearAMask']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>Jason</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>When your cat has more baking soda than Ninja ...</td>\n",
       "      <td>2011-12-21 04:41:30</td>\n",
       "      <td>150</td>\n",
       "      <td>182</td>\n",
       "      <td>7295</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:16</td>\n",
       "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>BEEHEMOTH ‚è≥</td>\n",
       "      <td>üá®üá¶ Canada</td>\n",
       "      <td>‚öíÔ∏è The Architects of Free Trade ‚öíÔ∏è Really Did ...</td>\n",
       "      <td>2016-07-13 17:21:59</td>\n",
       "      <td>1623</td>\n",
       "      <td>2160</td>\n",
       "      <td>98000</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:15</td>\n",
       "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>Gary DelPonte</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Global UX UI Visual Designer. StoryTeller, Mus...</td>\n",
       "      <td>2009-10-27 17:43:13</td>\n",
       "      <td>1338</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:14</td>\n",
       "      <td>More than 1,200 students test positive for #CO...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>TUKY II</td>\n",
       "      <td>Aliwal North, South Africa</td>\n",
       "      <td>TOKELO SEKHOPA | TUKY II | LAST BORN | EISH TU...</td>\n",
       "      <td>2018-04-14 17:30:07</td>\n",
       "      <td>97</td>\n",
       "      <td>1697</td>\n",
       "      <td>566</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:08</td>\n",
       "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179108 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_name               user_location  \\\n",
       "0                       ·èâ·é•‚òª’¨ÍÇÖœÆ                  astroworld   \n",
       "1                Tom Basile üá∫üá∏                New York, NY   \n",
       "2              Time4fisticuffs            Pewee Valley, KY   \n",
       "3                  ethel mertz        Stuck in the Middle    \n",
       "4                     DIPR-J&K           Jammu and Kashmir   \n",
       "...                        ...                         ...   \n",
       "179103  AJIMATI AbdulRahman O.             Ilorin, Nigeria   \n",
       "179104                   Jason                     Ontario   \n",
       "179105             BEEHEMOTH ‚è≥                   üá®üá¶ Canada   \n",
       "179106           Gary DelPonte               New York City   \n",
       "179107                 TUKY II  Aliwal North, South Africa   \n",
       "\n",
       "                                         user_description  \\\n",
       "0       wednesday addams as a disney princess keepin i...   \n",
       "1       Husband, Father, Columnist & Commentator. Auth...   \n",
       "2       #Christian #Catholic #Conservative #Reagan #Re...   \n",
       "3       #Browns #Indians #ClevelandProud #[]_[] #Cavs ...   \n",
       "4       üñäÔ∏èOfficial Twitter handle of Department of Inf...   \n",
       "...                                                   ...   \n",
       "179103    Animal Scientist|| Muslim|| Real Madrid/Chelsea   \n",
       "179104  When your cat has more baking soda than Ninja ...   \n",
       "179105  ‚öíÔ∏è The Architects of Free Trade ‚öíÔ∏è Really Did ...   \n",
       "179106  Global UX UI Visual Designer. StoryTeller, Mus...   \n",
       "179107  TOKELO SEKHOPA | TUKY II | LAST BORN | EISH TU...   \n",
       "\n",
       "               user_created  user_followers  user_friends  user_favourites  \\\n",
       "0       2017-05-26 05:46:42             624           950            18775   \n",
       "1       2009-04-16 20:06:23            2253          1677               24   \n",
       "2       2009-02-28 18:57:41            9275          9525             7254   \n",
       "3       2019-03-07 01:45:06             197           987             1488   \n",
       "4       2017-02-12 06:45:15          101009           168              101   \n",
       "...                     ...             ...           ...              ...   \n",
       "179103  2013-12-30 18:59:19             412          1609             1062   \n",
       "179104  2011-12-21 04:41:30             150           182             7295   \n",
       "179105  2016-07-13 17:21:59            1623          2160            98000   \n",
       "179106  2009-10-27 17:43:13            1338          1111                0   \n",
       "179107  2018-04-14 17:30:07              97          1697              566   \n",
       "\n",
       "        user_verified                 date  \\\n",
       "0               False  2020-07-25 12:27:21   \n",
       "1                True  2020-07-25 12:27:17   \n",
       "2               False  2020-07-25 12:27:14   \n",
       "3               False  2020-07-25 12:27:10   \n",
       "4               False  2020-07-25 12:27:08   \n",
       "...               ...                  ...   \n",
       "179103          False  2020-08-29 19:44:21   \n",
       "179104          False  2020-08-29 19:44:16   \n",
       "179105          False  2020-08-29 19:44:15   \n",
       "179106          False  2020-08-29 19:44:14   \n",
       "179107          False  2020-08-29 19:44:08   \n",
       "\n",
       "                                                     text  \\\n",
       "0       If I smelled the scent of hand sanitizers toda...   \n",
       "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3       @brookbanktv The one gift #COVID19 has give me...   \n",
       "4       25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                                                   ...   \n",
       "179103  Thanks @IamOhmai for nominating me for the @WH...   \n",
       "179104  2020! The year of insanity! Lol! #COVID19 http...   \n",
       "179105  @CTVNews A powerful painting by Juan Lucena. I...   \n",
       "179106  More than 1,200 students test positive for #CO...   \n",
       "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...   \n",
       "\n",
       "                                 hashtags               source  is_retweet  \n",
       "0                                     NaN   Twitter for iPhone       False  \n",
       "1                                     NaN  Twitter for Android       False  \n",
       "2                             ['COVID19']  Twitter for Android       False  \n",
       "3                             ['COVID19']   Twitter for iPhone       False  \n",
       "4       ['CoronaVirusUpdates', 'COVID19']  Twitter for Android       False  \n",
       "...                                   ...                  ...         ...  \n",
       "179103                      ['WearAMask']  Twitter for Android       False  \n",
       "179104                        ['COVID19']  Twitter for Android       False  \n",
       "179105                                NaN      Twitter Web App       False  \n",
       "179106                        ['COVID19']   Twitter for iPhone       False  \n",
       "179107                                NaN  Twitter for Android       False  \n",
       "\n",
       "[179108 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.apply(lambda x: x.astype(str).str.lower()) # the whole dataset is converted into lowercase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load text cleaning package\n",
    "import neattext as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-4db2ede3485d>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-4db2ede3485d>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    result = get_clean_data_column(new_column_name='cleaning_user_name',column_name='user_name')df[['text','cleaning_tweets']].head(20)\u001b[0m\n\u001b[1;37m                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_clean_data_column (new_column_name , column_name ):\n",
    "    df[new_column_name] = df[column_name].apply(nfx.remove_emojis)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_numbers)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_punctuations)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_special_characters)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_multiple_spaces)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_stopwords)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_hashtags)\n",
    "    df[new_column_name] = df[new_column_name].apply(nfx.remove_userhandles)\n",
    "    return df[new_column_name]\n",
    "result = get_clean_data_column(new_column_name='cleaning_user_name',column_name='user_name')df[['text','cleaning_tweets']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clean_data_column(new_column_name='cleaning_tweets',column_name='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['user_name','cleaning_user_name']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['user_name','cleaning_user_name']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text','cleaning_tweets']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_list (new_column_name):\n",
    "    clean_list = df[new_column_name].apply(nfx.remove_stopwords).tolist()\n",
    "    return clean_list\n",
    "result = get_clean_list('cleaning_user_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token (function_name):\n",
    "    tokens = [token for line in function_name for token in line.split()]\n",
    "    return tokens \n",
    "result123 = get_token(get_clean_list('cleaning_user_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_lemmatization(input_str_name):\n",
    "    input_str =input_str_name \n",
    "    for i in input_str:\n",
    "        a = nltk.word_tokenize(i)\n",
    "        for word in a:\n",
    "            print(lemmatizer.lemmatize(word))\n",
    "result = get_lemmatization(get_token(get_clean_list('cleaning_user_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_collection (docx,nums=30):\n",
    "    word_tokens = Counter(docx)\n",
    "    most_common = word_tokens.most_common(nums)\n",
    "    result = dict(most_common)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_token_collection(get_token(get_clean_list(\"cleaning_user_name\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common (token):\n",
    "    most_common = get_token_collection(token)\n",
    "    user_info_df = pd.DataFrame(most_common.items(),columns=['words','score'])\n",
    "    return user_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result45 = get_most_common(get_token_collection(get_token(get_clean_list(\"cleaning_user_name\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_time_date(column_name,new_column_name_year,new_column_name_month,new_column_name_day,new_column_name_hour,new_column_name_minute,new_column_name_second):\n",
    "    df[column_name] = pd.to_datetime(df[column_name])#it is in object type to convert into datetime \n",
    "    df[new_column_name_year]=df[column_name].dt.year\n",
    "    df[new_column_name_month]=df[column_name].dt.month\n",
    "    df[new_column_name_day]=df[column_name].dt.day\n",
    "    df[new_column_name_hour]=df[column_name].dt.hour\n",
    "    df[new_column_name_minute]=df[column_name].dt.minute\n",
    "    df[new_column_name_second]=df[column_name].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_time_date(column_name = 'user_created', new_column_name_year = 'years', new_column_name_month = 'months', new_column_name_day = 'days',new_column_name_hour = 'hours',new_column_name_minute='minute',new_column_name_second='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['user_created','years','months','days','hours','minute','second']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot( x = 'words', y = 'score', data=result45)\n",
    "plt.xticks(rotation =45)\n",
    "plt.title(\"Most_Common_User_Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "def plot_wordcloud(docx):\n",
    "    my_wordcloud = WordCloud().generate(docx)\n",
    "    plt.imshow(my_wordcloud,interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name_docx = ' '.join(result123)\n",
    "plot_wordcloud(user_name_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "    if sentiment_polarity > 0:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif sentiment_polarity < 0 :\n",
    "        sentiment_label = 'Negative'\n",
    "    else:\n",
    "        sentiment_label = 'Natural'\n",
    "    result = {'Polarity':sentiment_polarity,\n",
    "            'Subjectivity':sentiment_subjectivity,\n",
    "            'Sentiment':sentiment_label}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function\n",
    "exl = df['cleaning_tweets'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment(exl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_results'] = df['cleaning_tweets'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_results'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see the result of sentiment result in form of table we use this\n",
    "pd.json_normalize(df['sentiment_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to join the columns of sentiment_result to dataset we use this\n",
    "df = df.join(pd.json_normalize(df['sentiment_results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_sentiment(name_of_sentiment):\n",
    "    natural_tweet = df[df['Sentiment']==name_of_sentiment]['cleaning_tweets']\n",
    "    return natural_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_specific_sentiment('Natural').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_specific_sentiment('Negative').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_specific_sentiment('Positive').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_list(tweet_list_name):\n",
    "    tweet_list_name = tweet_list_name.apply(nfx.remove_stopwords).tolist()\n",
    "    return tweet_list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweet_list(negative_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweet_list(positive_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweet_list(natural_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pnn_token(pnn_list_name):\n",
    "    pnn_token = [token for line in pnn_list_name for token in line.split()]\n",
    "    return pnn_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pnn_token(positive_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pnn_token(negative_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pnn_token(natural_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Sentiment'] == 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
